(base) C:\Users\Johor>conda activate mm

(mm) C:\Users\Johor>mlagents-learn C:\Users\Johor\results\configuration.yaml --env=C:\Users\Johor\bmm\mm2 --time-scale=1 --num-envs=5 --run-id=test25

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙25 experiment

 Version information:
  ml-agents: 0.29.0,
  ml-agents-envs: 0.29.0,
  Communicator API: 1.5.0,
  PyTorch: 1.7.1+cu110
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Hyperparameters for behavior name Move to Goal:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   32
          buffer_size:  2048
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      None
        keep_checkpoints:       5
        checkpoint_interval:    50000
        max_steps:      500000
        time_horizon:   320
        summary_freq:   30000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Move to Goal. Step: 30000. Time Elapsed: 177.080 s. Mean Reward: -1.821. Std of Reward: 2.421. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-49914.onnx
[INFO] Move to Goal. Step: 60000. Time Elapsed: 349.658 s. Mean Reward: -1.056. Std of Reward: 2.801. Training.
[INFO] Move to Goal. Step: 90000. Time Elapsed: 522.527 s. Mean Reward: -0.775. Std of Reward: 2.725. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-99957.onnx
[INFO] Move to Goal. Step: 120000. Time Elapsed: 693.152 s. Mean Reward: -0.414. Std of Reward: 2.694. Training.
[INFO] Move to Goal. Step: 150000. Time Elapsed: 861.712 s. Mean Reward: -0.163. Std of Reward: 2.712. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-149950.onnx
[INFO] Move to Goal. Step: 180000. Time Elapsed: 1025.140 s. Mean Reward: -0.139. Std of Reward: 2.642. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-199950.onnx
[INFO] Move to Goal. Step: 210000. Time Elapsed: 1190.334 s. Mean Reward: -0.088. Std of Reward: 2.657. Training.
[INFO] Move to Goal. Step: 240000. Time Elapsed: 1354.146 s. Mean Reward: -0.133. Std of Reward: 2.678. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-249966.onnx
[INFO] Move to Goal. Step: 270000. Time Elapsed: 1528.876 s. Mean Reward: 0.108. Std of Reward: 2.772. Training.
[INFO] Move to Goal. Step: 300000. Time Elapsed: 1705.229 s. Mean Reward: 0.093. Std of Reward: 2.738. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-299978.onnx
[INFO] Move to Goal. Step: 330000. Time Elapsed: 1880.753 s. Mean Reward: 0.057. Std of Reward: 2.725. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-349998.onnx
[INFO] Move to Goal. Step: 360000. Time Elapsed: 2060.281 s. Mean Reward: 0.070. Std of Reward: 2.713. Training.
[INFO] Move to Goal. Step: 390000. Time Elapsed: 2238.412 s. Mean Reward: 0.065. Std of Reward: 2.728. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-399955.onnx
[INFO] Move to Goal. Step: 420000. Time Elapsed: 2419.397 s. Mean Reward: 0.284. Std of Reward: 2.810. Training.
[INFO] Move to Goal. Step: 450000. Time Elapsed: 2598.376 s. Mean Reward: 0.277. Std of Reward: 2.806. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-449994.onnx
[INFO] Move to Goal. Step: 480000. Time Elapsed: 2774.226 s. Mean Reward: 0.197. Std of Reward: 2.788. Training.
[INFO] Exported results\test25\Move to Goal\Move to Goal-499988.onnx
[INFO] Exported results\test25\Move to Goal\Move to Goal-500014.onnx
[INFO] Copied results\test25\Move to Goal\Move to Goal-500014.onnx to results\test25\Move to Goal.onnx.

(mm) C:\Users\Johor>mlagents-learn C:\Users\Johor\results\configuration.yaml --env=C:\Users\Johor\bmm\mm2 --time-scale=1 --num-envs=5 --run-id=test26

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙

 Version information:
  ml-agents: 0.29.0,
  ml-agents-envs: 0.29.0,
  Communicator API: 1.5.0,
  PyTorch: 1.7.1+cu110
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Hyperparameters for behavior name Move to Goal:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   32
          buffer_size:  2048
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      None
        keep_checkpoints:       5
        checkpoint_interval:    50000
        max_steps:      1000000
        time_horizon:   320
        summary_freq:   30000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Move to Goal. Step: 30000. Time Elapsed: 183.283 s. Mean Reward: -1.853. Std of Reward: 2.432. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-49869.onnx
[INFO] Move to Goal. Step: 60000. Time Elapsed: 359.930 s. Mean Reward: -1.520. Std of Reward: 2.573. Training.
[INFO] Move to Goal. Step: 90000. Time Elapsed: 535.556 s. Mean Reward: -0.738. Std of Reward: 2.702. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-99983.onnx
[INFO] Move to Goal. Step: 120000. Time Elapsed: 709.499 s. Mean Reward: -0.333. Std of Reward: 2.744. Training.
[INFO] Move to Goal. Step: 150000. Time Elapsed: 887.646 s. Mean Reward: -0.143. Std of Reward: 2.943. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-149881.onnx
[INFO] Move to Goal. Step: 180000. Time Elapsed: 1065.964 s. Mean Reward: -0.220. Std of Reward: 2.838. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-199956.onnx
[INFO] Move to Goal. Step: 210000. Time Elapsed: 1244.708 s. Mean Reward: -0.033. Std of Reward: 2.792. Training.
[INFO] Move to Goal. Step: 240000. Time Elapsed: 1423.146 s. Mean Reward: 0.017. Std of Reward: 2.796. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-249964.onnx
[INFO] Move to Goal. Step: 270000. Time Elapsed: 1606.481 s. Mean Reward: -0.032. Std of Reward: 2.785. Training.
[INFO] Move to Goal. Step: 300000. Time Elapsed: 1785.777 s. Mean Reward: 0.199. Std of Reward: 2.837. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-299975.onnx
[INFO] Move to Goal. Step: 330000. Time Elapsed: 1965.104 s. Mean Reward: 0.233. Std of Reward: 2.804. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-349963.onnx
[INFO] Move to Goal. Step: 360000. Time Elapsed: 2147.127 s. Mean Reward: 0.237. Std of Reward: 2.839. Training.
[INFO] Move to Goal. Step: 390000. Time Elapsed: 2327.863 s. Mean Reward: 0.186. Std of Reward: 2.770. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-399988.onnx
[INFO] Move to Goal. Step: 420000. Time Elapsed: 2510.952 s. Mean Reward: 0.300. Std of Reward: 2.830. Training.
[INFO] Move to Goal. Step: 450000. Time Elapsed: 2693.665 s. Mean Reward: 0.183. Std of Reward: 2.788. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-449943.onnx
[INFO] Move to Goal. Step: 480000. Time Elapsed: 2879.009 s. Mean Reward: 0.280. Std of Reward: 2.814. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-499998.onnx
[INFO] Move to Goal. Step: 510000. Time Elapsed: 3061.485 s. Mean Reward: 0.316. Std of Reward: 2.807. Training.
[INFO] Move to Goal. Step: 540000. Time Elapsed: 3246.225 s. Mean Reward: 0.418. Std of Reward: 2.865. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-549986.onnx
[INFO] Move to Goal. Step: 570000. Time Elapsed: 3428.678 s. Mean Reward: 0.468. Std of Reward: 2.884. Training.
[INFO] Move to Goal. Step: 600000. Time Elapsed: 3611.742 s. Mean Reward: 0.378. Std of Reward: 2.832. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-599992.onnx
[INFO] Move to Goal. Step: 630000. Time Elapsed: 3797.269 s. Mean Reward: 0.566. Std of Reward: 2.935. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-649971.onnx
[INFO] Move to Goal. Step: 660000. Time Elapsed: 3979.532 s. Mean Reward: 0.476. Std of Reward: 2.855. Training.
[INFO] Move to Goal. Step: 690000. Time Elapsed: 4163.566 s. Mean Reward: 0.670. Std of Reward: 2.937. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-699956.onnx
[INFO] Move to Goal. Step: 720000. Time Elapsed: 4346.042 s. Mean Reward: 0.307. Std of Reward: 2.807. Training.
[INFO] Move to Goal. Step: 750000. Time Elapsed: 4530.796 s. Mean Reward: 0.417. Std of Reward: 2.834. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-749980.onnx
[INFO] Move to Goal. Step: 780000. Time Elapsed: 4713.553 s. Mean Reward: 0.517. Std of Reward: 2.881. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-799974.onnx
[INFO] Move to Goal. Step: 810000. Time Elapsed: 4898.536 s. Mean Reward: 0.440. Std of Reward: 2.865. Training.
[INFO] Move to Goal. Step: 840000. Time Elapsed: 5081.097 s. Mean Reward: 0.549. Std of Reward: 2.864. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-849999.onnx
[INFO] Move to Goal. Step: 870000. Time Elapsed: 5263.104 s. Mean Reward: 0.622. Std of Reward: 2.905. Training.
[INFO] Move to Goal. Step: 900000. Time Elapsed: 5446.215 s. Mean Reward: 0.274. Std of Reward: 2.850. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-899996.onnx
[INFO] Move to Goal. Step: 930000. Time Elapsed: 5628.341 s. Mean Reward: 0.581. Std of Reward: 2.899. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-949920.onnx
[INFO] Move to Goal. Step: 960000. Time Elapsed: 5812.510 s. Mean Reward: 0.302. Std of Reward: 2.806. Training.
[INFO] Move to Goal. Step: 990000. Time Elapsed: 5993.176 s. Mean Reward: 0.447. Std of Reward: 2.853. Training.
[INFO] Exported results\test26\Move to Goal\Move to Goal-999934.onnx
[INFO] Exported results\test26\Move to Goal\Move to Goal-1000032.onnx
[INFO] Copied results\test26\Move to Goal\Move to Goal-1000032.onnx to results\test26\Move to Goal.onnx.

(mm) C:\Users\Johor>mlagents-learn C:\Users\Johor\results\configuration.yaml --env=C:\Users\Johor\bmm\mm2 --time-scale=1 --num-envs=2 --run-id=test260

            ┐  ╖
        ╓╖╬│╡  ││╬╖╖
    ╓╖╬│││││┘  ╬│││││╬╖
 ╖╬│││││╬╜        ╙╬│││││╖╖                               ╗╗╗
 ╬╬╬╬╖││╦╖        ╖╬││╗╣╣╣╬      ╟╣╣╬    ╟╣╣╣             ╜╜╜  ╟╣╣
 ╬╬╬╬╬╬╬╬╖│╬╖╖╓╬╪│╓╣╣╣╣╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╒╣╣╖╗╣╣╣╗   ╣╣╣ ╣╣╣╣╣╣ ╟╣╣╖   ╣╣╣
 ╬╬╬╬┐  ╙╬╬╬╬│╓╣╣╣╝╜  ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╣╙ ╙╣╣╣  ╣╣╣ ╙╟╣╣╜╙  ╫╣╣  ╟╣╣
 ╬╬╬╬┐     ╙╬╬╣╣      ╫╣╣╣╬      ╟╣╣╬    ╟╣╣╣ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣     ╣╣╣┌╣╣╜
 ╬╬╬╜       ╬╬╣╣      ╙╝╣╣╬      ╙╣╣╣╗╖╓╗╣╣╣╜ ╟╣╣╬   ╣╣╣  ╣╣╣  ╟╣╣╦╓    ╣╣╣╣╣
 ╙   ╓╦╖    ╬╬╣╣   ╓╗╗╖            ╙╝╣╣╣╣╝╜   ╘╝╝╜   ╝╝╝  ╝╝╝   ╙╣╣╣    ╟╣╣╣
   ╩╬╬╬╬╬╬╦╦╬╬╣╣╗╣╣╣╣╣╣╣╝                                             ╫╣╣╣╣
      ╙╬╬╬╬╬╬╬╣╣╣╣╣╣╝╜
          ╙╬╬╬╣╣╣╜
             ╙26_0 experiment

 Version information:
  ml-agents: 0.29.0,
  ml-agents-envs: 0.29.0,
  Communicator API: 1.5.0,
  PyTorch: 1.7.1+cu110
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected to Unity environment with package version 2.0.1 and communication version 1.5.0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Connected new brain: Move to Goal?team=0
[INFO] Hyperparameters for behavior name Move to Goal:
        trainer_type:   ppo
        hyperparameters:
          batch_size:   32
          buffer_size:  2048
          learning_rate:        0.0003
          beta: 0.005
          epsilon:      0.2
          lambd:        0.95
          num_epoch:    3
          learning_rate_schedule:       linear
          beta_schedule:        linear
          epsilon_schedule:     linear
        network_settings:
          normalize:    False
          hidden_units: 128
          num_layers:   2
          vis_encode_type:      simple
          memory:       None
          goal_conditioning_type:       hyper
          deterministic:        False
        reward_signals:
          extrinsic:
            gamma:      0.99
            strength:   1.0
            network_settings:
              normalize:        False
              hidden_units:     128
              num_layers:       2
              vis_encode_type:  simple
              memory:   None
              goal_conditioning_type:   hyper
              deterministic:    False
        init_path:      None
        keep_checkpoints:       5
        checkpoint_interval:    50000
        max_steps:      1000000
        time_horizon:   320
        summary_freq:   30000
        threaded:       False
        self_play:      None
        behavioral_cloning:     None
[INFO] Move to Goal. Step: 30000. Time Elapsed: 176.269 s. Mean Reward: -1.949. Std of Reward: 2.395. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-49920.onnx
[INFO] Move to Goal. Step: 60000. Time Elapsed: 351.970 s. Mean Reward: -1.376. Std of Reward: 2.678. Training.
[INFO] Move to Goal. Step: 90000. Time Elapsed: 527.118 s. Mean Reward: -0.687. Std of Reward: 2.721. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-99966.onnx
[INFO] Move to Goal. Step: 120000. Time Elapsed: 700.255 s. Mean Reward: -0.354. Std of Reward: 2.731. Training.
[INFO] Move to Goal. Step: 150000. Time Elapsed: 875.871 s. Mean Reward: -0.114. Std of Reward: 2.796. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-149949.onnx
[INFO] Move to Goal. Step: 180000. Time Elapsed: 1052.444 s. Mean Reward: -0.306. Std of Reward: 2.800. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-199943.onnx
[INFO] Move to Goal. Step: 210000. Time Elapsed: 1226.010 s. Mean Reward: -0.107. Std of Reward: 2.727. Training.
[INFO] Move to Goal. Step: 240000. Time Elapsed: 1402.611 s. Mean Reward: 0.229. Std of Reward: 2.832. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-249976.onnx
[INFO] Move to Goal. Step: 270000. Time Elapsed: 1581.911 s. Mean Reward: 0.251. Std of Reward: 2.875. Training.
[INFO] Move to Goal. Step: 300000. Time Elapsed: 1757.836 s. Mean Reward: 0.180. Std of Reward: 2.825. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-299867.onnx
[INFO] Move to Goal. Step: 330000. Time Elapsed: 1937.115 s. Mean Reward: 0.261. Std of Reward: 2.878. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-349993.onnx
[INFO] Move to Goal. Step: 360000. Time Elapsed: 2112.303 s. Mean Reward: 0.223. Std of Reward: 2.876. Training.
[INFO] Move to Goal. Step: 390000. Time Elapsed: 2288.937 s. Mean Reward: 0.379. Std of Reward: 2.920. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-399986.onnx
[INFO] Move to Goal. Step: 420000. Time Elapsed: 2467.532 s. Mean Reward: 0.444. Std of Reward: 2.943. Training.
[INFO] Move to Goal. Step: 450000. Time Elapsed: 2643.565 s. Mean Reward: 0.624. Std of Reward: 2.988. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-449941.onnx
[INFO] Move to Goal. Step: 480000. Time Elapsed: 2822.797 s. Mean Reward: 0.830. Std of Reward: 3.033. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-499981.onnx
[INFO] Move to Goal. Step: 510000. Time Elapsed: 2998.789 s. Mean Reward: 0.882. Std of Reward: 3.051. Training.
[INFO] Move to Goal. Step: 540000. Time Elapsed: 3175.512 s. Mean Reward: 1.186. Std of Reward: 3.096. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-549987.onnx
[INFO] Move to Goal. Step: 570000. Time Elapsed: 3354.257 s. Mean Reward: 0.980. Std of Reward: 3.067. Training.
[INFO] Move to Goal. Step: 600000. Time Elapsed: 3530.338 s. Mean Reward: 0.973. Std of Reward: 3.070. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-599974.onnx
[INFO] Move to Goal. Step: 630000. Time Elapsed: 3709.195 s. Mean Reward: 1.163. Std of Reward: 3.057. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-649982.onnx
[INFO] Move to Goal. Step: 660000. Time Elapsed: 3886.971 s. Mean Reward: 1.280. Std of Reward: 3.079. Training.
[INFO] Move to Goal. Step: 690000. Time Elapsed: 4063.972 s. Mean Reward: 1.212. Std of Reward: 3.070. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-699981.onnx
[INFO] Move to Goal. Step: 720000. Time Elapsed: 4242.399 s. Mean Reward: 1.439. Std of Reward: 3.062. Training.
[INFO] Move to Goal. Step: 750000. Time Elapsed: 4419.423 s. Mean Reward: 1.324. Std of Reward: 3.091. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-749931.onnx
[INFO] Move to Goal. Step: 780000. Time Elapsed: 4598.859 s. Mean Reward: 1.331. Std of Reward: 3.103. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-799985.onnx
[INFO] Move to Goal. Step: 810000. Time Elapsed: 4775.065 s. Mean Reward: 1.474. Std of Reward: 3.106. Training.
[INFO] Move to Goal. Step: 840000. Time Elapsed: 4953.848 s. Mean Reward: 1.220. Std of Reward: 3.083. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-849962.onnx
[INFO] Move to Goal. Step: 870000. Time Elapsed: 5130.160 s. Mean Reward: 1.498. Std of Reward: 3.102. Training.
[INFO] Move to Goal. Step: 900000. Time Elapsed: 5309.813 s. Mean Reward: 1.310. Std of Reward: 3.079. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-899990.onnx
[INFO] Move to Goal. Step: 930000. Time Elapsed: 5486.709 s. Mean Reward: 1.445. Std of Reward: 3.107. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-949982.onnx
[INFO] Move to Goal. Step: 960000. Time Elapsed: 5662.594 s. Mean Reward: 1.264. Std of Reward: 3.105. Training.
[INFO] Move to Goal. Step: 990000. Time Elapsed: 5842.554 s. Mean Reward: 1.369. Std of Reward: 3.087. Training.
[INFO] Exported results\test260\Move to Goal\Move to Goal-999986.onnx
[INFO] Exported results\test260\Move to Goal\Move to Goal-1000029.onnx
[INFO] Copied results\test260\Move to Goal\Move to Goal-1000029.onnx to results\test260\Move to Goal.onnx.

(mm) C:\Users\Johor>
